

2025-03-25 
04:04 PM


Tags: [[Linear Algebra]], [[Rank & Nullity Theorem]], [[Matrix Determinants]], [[Gaussian Elimination]], [[Column & Row Space]], [[Matrix Invertibility]], [[Fundamental Subspaces]], [[Discrete Math]], [[Function & Relations]], [[Proof Techniques]]


## Reference:
https://learn.zybooks.com/zybook/UNCCMATH2164DiaoSpring2025/chapter/5/section/5


##### Section Summary:
- "5.5 Rank and Nullity" introduces the concept of **rank** and make a connection between the **dimension of the four fundamental subspaces**, the **existence of a solution to a system of linear equations**, and the **invertibility of a matrix**. 
- Computing the **rank** are discussed in the section
- One of the main results of linear algebra, the **rank-nullity theorem** is introduced in this section. 
##### Section Objectives:
- Identify the rank of a matrix.
- Use the determinant of a matrix to find the rank.
- Use the rank-nullity theorem to find the dimensions of fundamental subspaces.
- Identify how rank relates to the column space and row space of a matrix.
- Use the rank-nullity theorem to identify dimensions of the four fundamental subspaces
- Use the rank-nullity theorem to identify the relationship between rank, nullity, invertibility, determinants, and bases of a subspace.

------------------------------------------------------------------------

**The Rank of a Matrix**:
The **rank** of a m x n matrix A, denoted by rank(A), is:
- The number of linearly independent column vectors in an echelon form of A.
- Since the number of linearly independent columns of A is equal to the number of pivot columns in an echelon form of A, 
	- Gaussian or or Gauss-Jordan elimination should be performed to find rank(A).
TL;DR:
- The **rank** of a matrix A indicates how many columns of A are **linearly independent**.
- To find the rank:
    1. Use **Gaussian elimination** or **Gauss-Jordan elimination** to convert the matrix to an **echelon form**.
    2. Count the number of **pivot columns** (columns with leading entries).
- The number of pivot columns you find is the **rank** of the matrix.

**Exampled 5.5.1: Finding the rank of the matrix** 
![[Screenshot 2025-03-25 at 4.33.14 PM.png]]
![[551example.pdf]]


**PA: Finding the rank of a matrix.**
![[IMG_A7187EDB2969-1.jpeg]]
![[IMG_5D26AA507943-1.jpeg]]


**PA: Understanding rank.**
![[Screenshot 2025-03-26 at 2.04.55 PM.png]]
- Rank(A) ≤ min{m, n} for an m×n Matrix
    - You can have at most one pivot per row and per column.
    - Therefore, the maximum number of pivots (linearly independent columns/rows) cannot exceed the smaller of m and n.
- Rank of the Identity Matrix I_n is n
    - The identity matrix I_n has a pivot (leading 1) in each of its n columns.
    - Hence, it has n linearly independent columns, so rank(I_n) = n.
- Rank of the Zero Matrix is 0
    - The zero matrix has all entries equal to zero, so every column is the zero vector.
    - All columns are linearly dependent, meaning there are no pivots.
    - Therefore, its rank is 0.
The rank of a matrix tells us how many of its columns (or rows) are linearly independent. Three core facts emerge:
1. You cannot have more linearly independent columns than min{m, n}.
2. A fully “independent” square matrix (like I_n) achieves the maximum possible rank, n.
3. A matrix with no nonzero entries (the zero matrix) has no independent columns, giving rank 0.
These principles highlight the spectrum of possible ranks for a matrix, from 0 (completely dependent) up to min{m, n} (maximally independent).


**Finding the rank using determinants**:
- The rank of a matrix A can also be computed using determinants.
	- By the Invertible Matrix Theorem, if the determinant of A is nonzero, then all columns of A are linearly independent.
	- This result also applies to a minor of order k of A and can be used to determine which columns of A are linearly independent.
		- A minor of order k of a matrix A is the determinant of a k × k sub-matrix of A.
- When a square matrix has a **nonzero determinant**, it means the matrix is **invertible** and all its columns are **linearly independent**.
- A **minor** of order k is simply the determinant of a smaller k×k section of the original matrix. If that minor is nonzero, it tells us those k columns are linearly independent.
	- In other words, if you can find the largest k×k sub-matrix whose determinant isn’t zero, you’ve found the **rank** of the matrix, because that indicates you have k independent columns.
	
	- **Finding the rank using minors**:
		- Let A be an m x n matrix. The rank of A is obtained as follows.
		  1. Find the minors of order k where k = min{m, n}. If a nonzero minor of order k exists, then rank(A) = k.
		2. If all minors of order k are zero, repeat step (1) for minors of order k - 1. Repeat the process until a nonzero minor is obtained.
		3. If all minors of order 1 are zero, then rank(A) = 0.

		- The **rank** of a matrix A can be found by looking at its **largest square sub-matrices** (of size k×k, where k = min(m, n)).
		- If **any** k×k sub-matrix has a **nonzero determinant**, that immediately tells you rank(A) = k.
		- If **none** of those k×k sub-matrices has a nonzero determinant, you **reduce** k by 1 and try again.
		- Continue until you find a sub-matrix whose determinant is nonzero.
		- If you get down to 1×1 sub-matrices (which are just single entries) and **all** of them are zero, then rank(A) = 0.

![[Screenshot 2025-03-26 at 5.01.46 PM.png]]

![[Screenshot 2025-03-26 at 5.05.01 PM.png]]
- Maximal Order of a Minor
    - A is a 3×4 matrix. The maximal order of a minor (a k×k sub-matrix determinant) is min{3, 4} = 3.
- 3 Linearly Independent Columns?
    - The 3×3 sub-matrices of A all have zero determinants.
    - This means there is no nonzero minor of order 3, so A does not have 3 linearly independent columns.
    - Therefore, the statement “A has 3 linearly independent columns” is false.
- Rank of A
    - Since all 3×3 minors are zero, the rank is less than 3.
    - However, a nonzero 2×2 minor exists, which shows rank(A) = 2.
- Because A is 3×4, the largest possible minor is 3×3. All 3×3 minors are zero, so the rank must be less than 3. We then check 2×2 minors and find at least one that is nonzero, confirming that the matrix has exactly 2 linearly independent columns (or rows). Hence, rank(A) = 2.


**Rank, row space, and column space**:
- Since the linearly independent columns of a matrix correspond to the minimal spanning set of the column space, the number of linearly independent columns of A forms a basis for the column space.
- Similarly, the linearly independent rows of A^T form a basis for the row space.
- The dimension of the column space and the rank of A^T is the dimension of the row space as stated in the theorems below:
	- **Theorem 5.5.2: The rank of the column space.**  
		- Given a matrix A, the dimension of the column space is denoted by dim(col(A)), which is the rank of A.
	- **Theorem 5.5.3: Rank and the row space.**  
		- The dimension of the row space is denoted by dim(row(A)), and it is equal to rank(A^T). 
		- Since rank(A^T) = rank(A), dim(row(A)) = rank(A).
	- **Theorem 5.5.4: The row space and the column space have the same dimension.**
		- Proof: rank(A) = rank(A^T).
		- Because rank can be obtained by computing minors, a k×k sub-matrix of A^T that does not vanish implies a corresponding sub-matrix in A, and so on.
		- Thus, rank(A) = dim(col(A)) = dim(row(A)).

	- **Column Space**: The set of all linear combinations of the columns of A. Its dimension equals the number of **linearly independent** columns, which is **rank(A)**.
	- **Row Space**: The set of all linear combinations of the rows of A. Its dimension equals the number of **linearly independent** rows, which is **rank(A^T)**.
	- **Equality of Ranks**: A key fact from linear algebra is that **rank(A) = rank(A^T)**. This means the dimension of the row space is the same as the dimension of the column space, even though they are subspaces of different “types” (rows vs. columns).
	- In other words, whether you look at rows or columns, you end up with the same **rank**. 
		- That’s why **dim(col(A)) = dim(row(A))**, and we say the row space and column space have the **same dimension**.
![[Screenshot 2025-03-26 at 5.24.49 PM.png]]
- **Rank of A^T = 4**
    - Since A and its transpose A^T have the **same rank**, and A is given to have rank 4, it follows that **rank(A^T) = 4**.
- **Dimension of the row space of A is 4** (not 5)
    - By definition, **dim(row(A)) = rank(A^T)**.
    - Since **rank(A^T) = 4**, **dim(row(A))** must be 4, not 5.
- **Basis of the column space has 4 vectors**
    - The **column space** of A has dimension equal to **rank(A)**.
    - Because **rank(A) = 4**, any basis for the column space must contain **4 linearly independent vectors**.

- A matrix A and its transpose A^T share the **same rank**, which tells us the dimensions of the row space and the column space are both equal to that rank. Specifically, if **rank(A) = 4**, then:
	- The row space has dimension 4 (so a basis would have 4 vectors).
	- The column space also has dimension 4 (so a basis would have 4 vectors).
	- And since rank(A^T) = rank(A), the transpose inherits the same rank of 4.
- In short, the row space and column space each have dimension 4, confirming the rank is 4.

- Since elementary row operations do not change the row space of a matrix, the rank of row equivalent matrices are the same.
- In particular, the rank of an augmented system (A | b) is equal to the rank of the corresponding reduced echelon form (A' | b').
- This result provides a relationship between the rank and column space of a matrix A and the existence of a solution to a system of linear equations Ax = b.
- Theorem 5.5.5: Rank, column space, and the existence of a solution to a system:
	- Let A ∈ R^(m×n), and b ∈ R^m.
	- The following statements are equivalent:
		- Ax = b has a solution
		- b ∈ col(A)
		- rank(A) = rank((A | b))

- **Row operations** do not change the rank of a matrix because they do not affect the fundamental row space.
- When we form the **augmented matrix** (A | b), we are effectively adding b as another column.
- If adding b does not increase the rank (meaning rank(A) = rank( (A | b) )), then **b lies in the column space** of A.
- This exactly means that the system **Ax = b** has at least one solution.


**The rank-nullity theorem**:
- The nullity of a matrix A is the dimension of the null space of A The intuition behind the relationship between rank and nullity is given in the animation below:
	- ![[Screenshot 2025-03-26 at 5.55.57 PM.png]]
	- ![[Screenshot 2025-03-26 at 5.57.07 PM.png]]
	- ![[Screenshot 2025-03-26 at 5.57.37 PM.png]]
	- ![[Screenshot 2025-03-26 at 6.02.15 PM.png]]

- **Challenge Activity: Rank and Nullity**
	- ![[Screenshot 2025-03-26 at 6.25.44 PM.png]]
		- ![[IMG_8E578437F370-1.jpeg]]
		- ![[Screenshot 2025-03-26 at 6.54.20 PM.png]]

	- ![[Screenshot 2025-03-26 at 7.02.45 PM.png]]
		- ![[IMG_FCBBDF63D6B5-1.jpeg]]

	- ![[Screenshot 2025-03-26 at 7.11.39 PM.png]]
		- ![[IMG_834679AD8E92-1.jpeg]]

	- ![[Screenshot 2025-03-26 at 7.22.47 PM.png]]
		- ![[Screenshot 2025-03-26 at 7.22.54 PM.png]]

	- ![[Screenshot 2025-03-26 at 7.23.39 PM.png]]
		- ![[IMG_4DD14C60A617-1.jpeg]]

	- ![[Screenshot 2025-03-26 at 7.41.06 PM.png]]
		- ![[Screenshot 2025-03-26 at 7.58.52 PM.png]]


**The Invertible Matrix Theorem**:
- The Invertible Matrix Theorem is restated to include results about rank and nullity of an n × n matrix.
	-   Let A be an n×n square matrix. Then the following statements are equivalent.
		- A is invertible.
		- A is row equivalent to the n×n identity matrix I_n.
		- A has n pivot positions.
		- The equation A x = 0 has only the trivial solution x = 0.
		- An n×n matrix C exists such that C A = I_n.
		- An n×n matrix D exists such that A D = I_n.
		- The transpose matrix A^T is invertible.
		- The determinant of A is nonzero.
		- The row vectors of A are linearly independent.
		- The column vectors of A are linearly independent.
		- The row vectors form a basis for R^n.
		- The column vectors form a basis for R^n.
		- A has rank n.
		- A has nullity 0.
- ![[Screenshot 2025-03-26 at 8.01.37 PM.png]]









